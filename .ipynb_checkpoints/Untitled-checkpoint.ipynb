{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Khang_cute\n"
     ]
    }
   ],
   "source": [
    "print(\"Khang_cute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "class CartPoleAgent:\n",
    "    def __init__(self,action_space):\n",
    "        #Database\n",
    "        self.db_observations = []\n",
    "        self.db_actions = []\n",
    "        self.db_rewards = []\n",
    "        self.db_values = []\n",
    "        self.action_space = action_space\n",
    "        self.K = 1000           #for K nearest neighbor\n",
    "        self.step = 0\n",
    "        self.ep = 0\n",
    "        self.iter = 0\n",
    "        self.gamma = 0.95\n",
    "        self.ep_start = 0\n",
    "    def dist(self, x, y):\n",
    "        leng = len(x)\n",
    "        ans = 0\n",
    "        for i in range(leng):\n",
    "            ans += (x[i]-y[i])**2\n",
    "        return ans\n",
    "    def act(self, observation, reward, done, info):\n",
    "        action = None\n",
    "        if (len(self.db_observations) < 823):\n",
    "            #explore\n",
    "            action = self.action_space.sample()\n",
    "        else:\n",
    "            #exploit\n",
    "            distance = [self.dist(x,observation) for x in self.db_observations]\n",
    "            sorted_idx = np.argsort(distance)\n",
    "            sorted_idx = sorted_idx[:min(self.K,len(sorted_idx))]\n",
    "            value_dict = defaultdict(int)\n",
    "            n_dict = defaultdict(int)\n",
    "            for i in sorted_idx:\n",
    "                value_dict[self.db_actions[i]] += self.db_values[i]\n",
    "                n_dict[self.db_actions[i]] += 1\n",
    "            for action,value in value_dict.items():\n",
    "                value_dict[action] /= n_dict[action]\n",
    "            value_array = [(value,action) for action, value in value_dict.items()]\n",
    "            value_array.sort(reverse = True)\n",
    "            action = value_array[0][1]\n",
    "            \n",
    "        \n",
    "        self.db_observations.append(observation)\n",
    "        self.db_actions.append(action)\n",
    "        self.db_rewards.append(0)\n",
    "        self.db_values.append(0)\n",
    "        if (self.iter >0):\n",
    "            self.db_rewards[self.iter-1] = reward\n",
    "        self.iter+=1\n",
    "        if (done):\n",
    "            self.db_values[self.iter-1] = reward\n",
    "            for i in reversed(range(self.ep_start,self.iter-1)):\n",
    "                self.db_values[i] = self.db_rewards[i] + self.gamma*self.db_values[i+1]\n",
    "            self.step = 0\n",
    "            \n",
    "            self.ep_start = self.iter\n",
    "        return action\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 has 42 frames\n",
      "episode 0 running reward 2.150000\n",
      "Episode 1 has 26 frames\n",
      "episode 1 running reward 3.392500\n",
      "Episode 2 has 15 frames\n",
      "episode 2 running reward 4.022875\n",
      "Episode 3 has 21 frames\n",
      "episode 3 running reward 4.921731\n",
      "Episode 4 has 22 frames\n",
      "episode 4 running reward 5.825645\n",
      "Episode 5 has 11 frames\n",
      "episode 5 running reward 6.134362\n",
      "Episode 6 has 12 frames\n",
      "episode 6 running reward 6.477644\n",
      "Episode 7 has 19 frames\n",
      "episode 7 running reward 7.153762\n",
      "Episode 8 has 33 frames\n",
      "episode 8 running reward 8.496074\n",
      "Episode 9 has 20 frames\n",
      "episode 9 running reward 9.121270\n",
      "Episode 10 has 25 frames\n",
      "episode 10 running reward 9.965207\n",
      "Episode 11 has 17 frames\n",
      "episode 11 running reward 10.366946\n",
      "Episode 12 has 19 frames\n",
      "episode 12 running reward 10.848599\n",
      "Episode 13 has 23 frames\n",
      "episode 13 running reward 11.506169\n",
      "Episode 14 has 30 frames\n",
      "episode 14 running reward 12.480861\n",
      "Episode 15 has 42 frames\n",
      "episode 15 running reward 14.006818\n",
      "Episode 16 has 31 frames\n",
      "episode 16 running reward 14.906477\n",
      "Episode 17 has 35 frames\n",
      "episode 17 running reward 15.961153\n",
      "Episode 18 has 40 frames\n",
      "episode 18 running reward 17.213095\n",
      "Episode 19 has 34 frames\n",
      "episode 19 running reward 18.102441\n",
      "Episode 20 has 19 frames\n",
      "episode 20 running reward 18.197319\n",
      "Episode 21 has 12 frames\n",
      "episode 21 running reward 17.937453\n",
      "Episode 22 has 28 frames\n",
      "episode 22 running reward 18.490580\n",
      "Episode 23 has 8 frames\n",
      "episode 23 running reward 18.016051\n",
      "Episode 24 has 17 frames\n",
      "episode 24 running reward 18.015248\n",
      "Episode 25 has 18 frames\n",
      "episode 25 running reward 18.064486\n",
      "Episode 26 has 27 frames\n",
      "episode 26 running reward 18.561262\n",
      "Episode 27 has 11 frames\n",
      "episode 27 running reward 18.233199\n",
      "Episode 28 has 24 frames\n",
      "episode 28 running reward 18.571539\n",
      "Episode 29 has 14 frames\n",
      "episode 29 running reward 18.392962\n",
      "Episode 30 has 13 frames\n",
      "episode 30 running reward 18.173314\n",
      "Episode 31 has 10 frames\n",
      "episode 31 running reward 17.814648\n",
      "Episode 32 has 21 frames\n",
      "episode 32 running reward 18.023916\n",
      "Episode 33 has 31 frames\n",
      "episode 33 running reward 18.722720\n",
      "Episode 34 has 28 frames\n",
      "episode 34 running reward 19.236584\n",
      "Episode 35 has 8 frames\n",
      "episode 35 running reward 18.724755\n",
      "Episode 36 has 8 frames\n",
      "episode 36 running reward 18.238517\n",
      "Episode 37 has 8 frames\n",
      "episode 37 running reward 17.776591\n",
      "Episode 38 has 9 frames\n",
      "episode 38 running reward 17.387761\n",
      "Episode 39 has 15 frames\n",
      "episode 39 running reward 17.318373\n",
      "Episode 40 has 11 frames\n",
      "episode 40 running reward 17.052455\n",
      "Episode 41 has 8 frames\n",
      "episode 41 running reward 16.649832\n",
      "Episode 42 has 12 frames\n",
      "episode 42 running reward 16.467340\n",
      "Episode 43 has 14 frames\n",
      "episode 43 running reward 16.393973\n",
      "Episode 44 has 9 frames\n",
      "episode 44 running reward 16.074275\n",
      "Episode 45 has 9 frames\n",
      "episode 45 running reward 15.770561\n",
      "Episode 46 has 15 frames\n",
      "episode 46 running reward 15.782033\n",
      "Episode 47 has 35 frames\n",
      "episode 47 running reward 16.792931\n",
      "Episode 48 has 14 frames\n",
      "episode 48 running reward 16.703285\n",
      "Episode 49 has 16 frames\n",
      "episode 49 running reward 16.718120\n",
      "Episode 50 has 15 frames\n",
      "episode 50 running reward 16.682214\n",
      "Episode 51 has 17 frames\n",
      "episode 51 running reward 16.748104\n",
      "Episode 52 has 16 frames\n",
      "episode 52 running reward 16.760699\n",
      "Episode 53 has 25 frames\n",
      "episode 53 running reward 17.222664\n",
      "Episode 54 has 62 frames\n",
      "episode 54 running reward 19.511530\n",
      "Episode 55 has 42 frames\n",
      "episode 55 running reward 20.685954\n",
      "Episode 56 has 50 frames\n",
      "episode 56 running reward 22.201656\n",
      "Episode 57 has 59 frames\n",
      "episode 57 running reward 24.091573\n",
      "Episode 58 has 32 frames\n",
      "episode 58 running reward 24.536995\n",
      "Episode 59 has 26 frames\n",
      "episode 59 running reward 24.660145\n",
      "Episode 60 has 27 frames\n",
      "episode 60 running reward 24.827138\n",
      "Episode 61 has 32 frames\n",
      "episode 61 running reward 25.235781\n",
      "Episode 62 has 44 frames\n",
      "episode 62 running reward 26.223992\n",
      "Episode 63 has 45 frames\n",
      "episode 63 running reward 27.212792\n",
      "Episode 64 has 33 frames\n",
      "episode 64 running reward 27.552153\n",
      "Episode 65 has 29 frames\n",
      "episode 65 running reward 27.674545\n",
      "Episode 66 has 43 frames\n",
      "episode 66 running reward 28.490818\n",
      "Episode 67 has 42 frames\n",
      "episode 67 running reward 29.216277\n",
      "Episode 68 has 85 frames\n",
      "episode 68 running reward 32.055463\n",
      "Episode 69 has 168 frames\n",
      "episode 69 running reward 38.902690\n",
      "Episode 70 has 80 frames\n",
      "episode 70 running reward 41.007555\n",
      "Episode 71 has 70 frames\n",
      "episode 71 running reward 42.507178\n",
      "Episode 72 has 62 frames\n",
      "episode 72 running reward 43.531819\n",
      "Episode 73 has 72 frames\n",
      "episode 73 running reward 45.005228\n",
      "Episode 74 has 87 frames\n",
      "episode 74 running reward 47.154966\n",
      "Episode 75 has 87 frames\n",
      "episode 75 running reward 49.197218\n",
      "Episode 76 has 67 frames\n",
      "episode 76 running reward 50.137357\n",
      "Episode 77 has 78 frames\n",
      "episode 77 running reward 51.580489\n",
      "Episode 78 has 76 frames\n",
      "episode 78 running reward 52.851465\n",
      "Episode 79 has 129 frames\n",
      "episode 79 running reward 56.708892\n",
      "Episode 80 has 76 frames\n",
      "episode 80 running reward 57.723447\n",
      "Episode 81 has 95 frames\n",
      "episode 81 running reward 59.637275\n",
      "Episode 82 has 71 frames\n",
      "episode 82 running reward 60.255411\n",
      "Episode 83 has 146 frames\n",
      "episode 83 running reward 64.592640\n",
      "Episode 84 has 65 frames\n",
      "episode 84 running reward 64.663008\n",
      "Episode 85 has 188 frames\n",
      "episode 85 running reward 70.879858\n",
      "Episode 86 has 144 frames\n",
      "episode 86 running reward 74.585865\n",
      "Episode 87 has 76 frames\n",
      "episode 87 running reward 74.706572\n",
      "Episode 88 has 145 frames\n",
      "episode 88 running reward 78.271243\n",
      "Episode 89 has 63 frames\n",
      "episode 89 running reward 77.557681\n",
      "Episode 90 has 199 frames\n",
      "episode 90 running reward 83.679797\n",
      "Episode 91 has 66 frames\n",
      "episode 91 running reward 82.845807\n",
      "Episode 92 has 81 frames\n",
      "episode 92 running reward 82.803517\n",
      "Episode 93 has 71 frames\n",
      "episode 93 running reward 82.263341\n",
      "Episode 94 has 139 frames\n",
      "episode 94 running reward 85.150174\n",
      "Episode 95 has 188 frames\n",
      "episode 95 running reward 90.342665\n",
      "Episode 96 has 199 frames\n",
      "episode 96 running reward 95.825532\n",
      "Episode 97 has 199 frames\n",
      "episode 97 running reward 101.034255\n",
      "Episode 98 has 199 frames\n",
      "episode 98 running reward 105.982543\n",
      "Episode 99 has 80 frames\n",
      "episode 99 running reward 104.733415\n",
      "Episode 100 has 134 frames\n",
      "episode 100 running reward 106.246745\n",
      "Episode 101 has 199 frames\n",
      "episode 101 running reward 110.934407\n",
      "Episode 102 has 199 frames\n",
      "episode 102 running reward 115.387687\n",
      "Episode 103 has 199 frames\n",
      "episode 103 running reward 119.618303\n",
      "Episode 104 has 127 frames\n",
      "episode 104 running reward 120.037388\n",
      "Episode 105 has 199 frames\n",
      "episode 105 running reward 124.035518\n",
      "Episode 106 has 110 frames\n",
      "episode 106 running reward 123.383742\n",
      "Episode 107 has 166 frames\n",
      "episode 107 running reward 125.564555\n",
      "Episode 108 has 124 frames\n",
      "episode 108 running reward 125.536327\n",
      "Episode 109 has 91 frames\n",
      "episode 109 running reward 123.859511\n",
      "Episode 110 has 111 frames\n",
      "episode 110 running reward 123.266535\n",
      "Episode 111 has 95 frames\n",
      "episode 111 running reward 121.903209\n",
      "Episode 112 has 104 frames\n",
      "episode 112 running reward 121.058048\n",
      "Episode 113 has 199 frames\n",
      "episode 113 running reward 125.005146\n",
      "Episode 114 has 140 frames\n",
      "episode 114 running reward 125.804889\n",
      "Episode 115 has 172 frames\n",
      "episode 115 running reward 128.164644\n",
      "Episode 116 has 71 frames\n",
      "episode 116 running reward 125.356412\n",
      "Episode 117 has 88 frames\n",
      "episode 117 running reward 123.538591\n",
      "Episode 118 has 121 frames\n",
      "episode 118 running reward 123.461662\n",
      "Episode 119 has 168 frames\n",
      "episode 119 running reward 125.738579\n",
      "Episode 120 has 199 frames\n",
      "episode 120 running reward 129.451650\n",
      "Episode 121 has 70 frames\n",
      "episode 121 running reward 126.529067\n",
      "Episode 122 has 94 frames\n",
      "episode 122 running reward 124.952614\n",
      "Episode 123 has 85 frames\n",
      "episode 123 running reward 123.004983\n",
      "Episode 124 has 144 frames\n",
      "episode 124 running reward 124.104734\n",
      "Episode 125 has 75 frames\n",
      "episode 125 running reward 121.699497\n",
      "Episode 126 has 199 frames\n",
      "episode 126 running reward 125.614522\n",
      "Episode 127 has 81 frames\n",
      "episode 127 running reward 123.433796\n",
      "Episode 128 has 83 frames\n",
      "episode 128 running reward 121.462107\n",
      "Episode 129 has 199 frames\n",
      "episode 129 running reward 125.389001\n",
      "Episode 130 has 83 frames\n",
      "episode 130 running reward 123.319551\n",
      "Episode 131 has 199 frames\n",
      "episode 131 running reward 127.153574\n",
      "Episode 132 has 199 frames\n",
      "episode 132 running reward 130.795895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 133 has 66 frames\n",
      "episode 133 running reward 127.606100\n",
      "Episode 134 has 157 frames\n",
      "episode 134 running reward 129.125795\n",
      "Episode 135 has 83 frames\n",
      "episode 135 running reward 126.869505\n",
      "Episode 136 has 74 frames\n",
      "episode 136 running reward 124.276030\n",
      "Episode 137 has 198 frames\n",
      "episode 137 running reward 128.012229\n",
      "Episode 138 has 171 frames\n",
      "episode 138 running reward 130.211617\n",
      "Episode 139 has 110 frames\n",
      "episode 139 running reward 129.251036\n",
      "Episode 140 has 199 frames\n",
      "episode 140 running reward 132.788485\n",
      "Episode 141 has 199 frames\n",
      "episode 141 running reward 136.149060\n",
      "Episode 142 has 106 frames\n",
      "episode 142 running reward 134.691607\n",
      "Episode 143 has 199 frames\n",
      "episode 143 running reward 137.957027\n",
      "Episode 144 has 128 frames\n",
      "episode 144 running reward 137.509176\n",
      "Episode 145 has 113 frames\n",
      "episode 145 running reward 136.333717\n",
      "Episode 146 has 199 frames\n",
      "episode 146 running reward 139.517031\n",
      "Episode 147 has 74 frames\n",
      "episode 147 running reward 136.291179\n",
      "Episode 148 has 81 frames\n",
      "episode 148 running reward 133.576620\n",
      "Episode 149 has 178 frames\n",
      "episode 149 running reward 135.847789\n",
      "Episode 150 has 199 frames\n",
      "episode 150 running reward 139.055400\n",
      "Episode 151 has 199 frames\n",
      "episode 151 running reward 142.102630\n",
      "Episode 152 has 199 frames\n",
      "episode 152 running reward 144.997498\n",
      "Episode 153 has 199 frames\n",
      "episode 153 running reward 147.747624\n",
      "Episode 154 has 199 frames\n",
      "episode 154 running reward 150.360242\n",
      "Episode 155 has 60 frames\n",
      "episode 155 running reward 145.892230\n",
      "Episode 156 has 199 frames\n",
      "episode 156 running reward 148.597619\n",
      "Episode 157 has 199 frames\n",
      "episode 157 running reward 151.167738\n",
      "Episode 158 has 142 frames\n",
      "episode 158 running reward 150.759351\n",
      "Episode 159 has 92 frames\n",
      "episode 159 running reward 147.871383\n",
      "Episode 160 has 96 frames\n",
      "episode 160 running reward 145.327814\n",
      "Episode 161 has 199 frames\n",
      "episode 161 running reward 148.061423\n",
      "Episode 162 has 196 frames\n",
      "episode 162 running reward 150.508352\n",
      "Episode 163 has 104 frames\n",
      "episode 163 running reward 148.232935\n",
      "Episode 164 has 199 frames\n",
      "episode 164 running reward 150.821288\n",
      "Episode 165 has 141 frames\n",
      "episode 165 running reward 150.380224\n",
      "Episode 166 has 144 frames\n",
      "episode 166 running reward 150.111212\n",
      "Episode 167 has 199 frames\n",
      "episode 167 running reward 152.605652\n",
      "Episode 168 has 199 frames\n",
      "episode 168 running reward 154.975369\n",
      "Episode 169 has 150 frames\n",
      "episode 169 running reward 154.776601\n",
      "Episode 170 has 199 frames\n",
      "episode 170 running reward 157.037771\n",
      "Episode 171 has 80 frames\n",
      "episode 171 running reward 153.235882\n",
      "Episode 172 has 199 frames\n",
      "episode 172 running reward 155.574088\n",
      "Episode 173 has 199 frames\n",
      "episode 173 running reward 157.795384\n",
      "Episode 174 has 121 frames\n",
      "episode 174 running reward 156.005614\n",
      "Episode 175 has 199 frames\n",
      "episode 175 running reward 158.205334\n",
      "Episode 176 has 199 frames\n",
      "episode 176 running reward 160.295067\n",
      "Episode 177 has 199 frames\n",
      "episode 177 running reward 162.280314\n",
      "Episode 178 has 199 frames\n",
      "episode 178 running reward 164.166298\n",
      "Episode 179 has 91 frames\n",
      "episode 179 running reward 160.557983\n",
      "Episode 180 has 85 frames\n",
      "episode 180 running reward 156.830084\n",
      "Episode 181 has 185 frames\n",
      "episode 181 running reward 158.288580\n",
      "Episode 182 has 123 frames\n",
      "episode 182 running reward 156.574151\n",
      "Episode 183 has 199 frames\n",
      "episode 183 running reward 158.745443\n",
      "Episode 184 has 199 frames\n",
      "episode 184 running reward 160.808171\n",
      "Episode 185 has 150 frames\n",
      "episode 185 running reward 160.317763\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7d3db9b418be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi_frame\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_FRAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0msum_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-0630c0ba6fb8>\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, observation, reward, done, info)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m#exploit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb_observations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0msorted_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0msorted_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-0630c0ba6fb8>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m#exploit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb_observations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0msorted_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0msorted_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-0630c0ba6fb8>\u001b[0m in \u001b[0;36mdist\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mans\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gym\n",
    "# Constant\n",
    "NUM_EPISODE = 200\n",
    "MAX_FRAME = 5000\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "agent = CartPoleAgent(env.action_space)\n",
    "reward = 0\n",
    "done = False\n",
    "running_reward = 0\n",
    "for i_episode in range(NUM_EPISODE):\n",
    "    ob = env.reset()\n",
    "    sum_reward = 0\n",
    "    for i_frame in range(MAX_FRAME):\n",
    "        env.render(mode='rgb_array')\n",
    "        action = agent.act(ob, reward, done, None)\n",
    "        ob, reward, done, info = env.step(action)\n",
    "        sum_reward += reward\n",
    "        if done:\n",
    "            print('Episode %d has %d frames' % (i_episode, i_frame))\n",
    "            break\n",
    "    running_reward = running_reward * 0.95 + sum_reward * 0.05\n",
    "    print('episode %d running reward %f' %(i_episode, running_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
